{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA DOWNLOAD\n",
    "To start this project, you need an addition data file.\n",
    "\n",
    "First you should download data from:\n",
    "https://pan.baidu.com/s/1KFui9zZKjRqzFkCJH5nenw\n",
    "    \n",
    "Then unzip it,create a data dir, and put it in data directory\n",
    "\n",
    "## After you do all that , the following file should be found:\n",
    "\n",
    "```python\n",
    "'data/segmented_train_seg_by_word.txt' \n",
    "```\n",
    "\n",
    "And that means you are good to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20000000 data/segmented_train_seg_by_word.txt\n"
     ]
    }
   ],
   "source": [
    "! wc -l data/segmented_train_seg_by_word.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import ProgressBar\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100.00 % [==================================================>] 10000000/10000000 \t used:49s eta:0 s"
     ]
    }
   ],
   "source": [
    "enline = None\n",
    "chline = None\n",
    "\n",
    "sentlength = 5\n",
    "\n",
    "enlines = []\n",
    "chlines = []\n",
    "pb = ProgressBar(worksum=10000000)\n",
    "pb.startjob()\n",
    "num = 0\n",
    "with open('data/segmented_train_seg_by_word.txt') as fhdl:\n",
    "    for line in fhdl:\n",
    "        num += 1\n",
    "        if num % 2 == 1:\n",
    "            enline = line\n",
    "            continue\n",
    "        else:\n",
    "            chline = line\n",
    "        \n",
    "        enlinesp = [i.lower() for i in enline.strip(\"\\n\").split()]\n",
    "        chlinesp = [i for i in chline.strip(\"\\n\").replace(' ','')]\n",
    "        if len(enlinesp) <= sentlength and len(chlinesp) <= sentlength:\n",
    "            enlines.append(enlinesp)\n",
    "            chlines.append(chlinesp)\n",
    "        if (num // 2) % 1000 == 0:\n",
    "            pb.complete(1000)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['deuces', 'the', 'winner', '.'],\n",
       " ['a', 'couple', 'of', 'what', '?'],\n",
       " ['a', 'pair', 'of', 'wives', '?'],\n",
       " ['husband', 'and', 'wife', '.'],\n",
       " ['couple', '.'],\n",
       " ['nice', 'couple', '.'],\n",
       " ['two', 'lovers', '.'],\n",
       " ['a', 'couple', 'getting', 'married', '.'],\n",
       " ['couple', 'of', 'newbies', '?'],\n",
       " ['a', 'couple', 'of', 'gunslingers', '.']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enlines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['一', '对', '二', '胜', '。'],\n",
       " ['一', '对', '什', '么', '？'],\n",
       " ['一', '对', '太', '太', '？'],\n",
       " ['一', '对', '夫', '妇', '。'],\n",
       " ['一', '对', '夫', '妻', '。'],\n",
       " ['一', '对', '好', '人', '。'],\n",
       " ['一', '对', '情', '人', '。'],\n",
       " ['一', '对', '新', '人', '。'],\n",
       " ['一', '对', '新', '手', '？'],\n",
       " ['一', '对', '枪', '手', '。']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chlines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103912, 103912)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chlines),len(enlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "enwords = []\n",
    "chwords = []\n",
    "for sent in enlines:\n",
    "    for enword in sent:\n",
    "        enwords.append(enword)\n",
    "        \n",
    "for sent in chlines:\n",
    "    for chword in sent:\n",
    "        chwords.append(chword)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 49461),\n",
       " ('?', 14511),\n",
       " ('the', 10472),\n",
       " ('i', 10013),\n",
       " (',', 9489),\n",
       " ('!', 8807),\n",
       " ('you', 7493),\n",
       " ('a', 6860),\n",
       " (\"'\", 5555),\n",
       " ('it', 5524)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(enwords).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('。', 44900),\n",
       " ('我', 15087),\n",
       " ('？', 14454),\n",
       " ('你', 9087),\n",
       " ('！', 8915),\n",
       " ('了', 8663),\n",
       " ('的', 8053),\n",
       " ('，', 7291),\n",
       " ('一', 6091),\n",
       " ('是', 5946)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(chwords).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21739, 4054)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(enwords)),len(set(chwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch2ind = {}\n",
    "ind2ch = {}\n",
    "en2ind = {}\n",
    "ind2en = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "specialchars = ['<eos>','<start>','<end>','<unk>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addchar(what2ind,ind2what,char):\n",
    "    if char in what2ind:\n",
    "        return \n",
    "    ind2what[len(what2ind)] = char\n",
    "    what2ind[char] = len(what2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for one in specialchars:\n",
    "    addchar(ch2ind,ind2ch,one)\n",
    "    addchar(en2ind,ind2en,one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word,_ in Counter(enwords).most_common(10000):\n",
    "    addchar(en2ind,ind2en,word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word,_ in Counter(chwords).most_common(10000):\n",
    "    addchar(ch2ind,ind2ch,word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10004, 4058)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en2ind),len(ch2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_x_in = []\n",
    "dat_y_in = []\n",
    "dat_y_out = []\n",
    "\n",
    "dat_x_len = []\n",
    "dat_y_len = []\n",
    "\n",
    "for ensent in enlines:\n",
    "    indsent = [en2ind.get(i,en2ind['<unk>']) for i in ensent]\n",
    "    indsent.append(en2ind['<eos>'])\n",
    "    dat_x_in.append(indsent)\n",
    "    dat_x_len.append(len(indsent))\n",
    "    \n",
    "for chsent in chlines:\n",
    "    indsent = [ch2ind.get(i,ch2ind['<unk>']) for i in chsent]\n",
    "    #indsent.append(ch2ind['<eos>'])\n",
    "    dat_y_in.append([ch2ind['<start>']] + indsent)\n",
    "    dat_y_out.append(indsent + [ch2ind['<end>']])\n",
    "    dat_y_len.append(len(indsent) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['couple', '.', '<eos>']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ind2en[i] for i in dat_x_in[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start>', '一', '对', '夫', '妻', '。']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ind2ch[i] for i in dat_y_in[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['一', '对', '夫', '妻', '。', '<end>']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ind2ch[i] for i in dat_y_out[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 6)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_x_len[4],dat_y_len[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103912, 103912, 103912, 103912, 103912)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dat_x_in),\\\n",
    "len(dat_y_in),\\\n",
    "len(dat_y_out),\\\n",
    "len(dat_x_len),\\\n",
    "len(dat_y_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.layers import core as layers_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0927 19:07:54.080381 4589176256 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/tflearn/helpers/summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "W0927 19:07:54.081264 4589176256 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/tflearn/helpers/trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "W0927 19:07:54.085538 4589176256 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/tflearn/collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "W0927 19:07:54.088059 4589176256 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/tflearn/config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "W0927 19:07:54.092186 4589176256 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/tflearn/config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "W0927 19:07:54.092915 4589176256 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/tflearn/config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tflearn\n",
    "tf.reset_default_graph()\n",
    "config = tf.ConfigProto(log_device_placement=True,allow_soft_placement = True)\n",
    "config.gpu_options.allow_growth = True\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "session = tf.Session(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 512\n",
    "num_units = 512\n",
    "batch_size = 128\n",
    "layer_number = 2\n",
    "max_grad = 1.0\n",
    "dropout = 0.2\n",
    "src_vocab_size = len(en2ind)\n",
    "target_vocat_size = len(ch2ind)\n",
    "seq_max_len = sentlength + 1\n",
    "maximum_iterations = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 19:07:54.147173 4589176256 deprecation.py:323] From <ipython-input-28-bd9d94bd0d72>:35: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W0927 19:07:54.148135 4589176256 deprecation.py:323] From <ipython-input-28-bd9d94bd0d72>:42: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "W0927 19:07:54.232762 4589176256 deprecation.py:506] From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:738: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0927 19:07:54.483128 4589176256 deprecation.py:323] From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.reset_default_graph()\n",
    "config = tf.ConfigProto(log_device_placement=True,allow_soft_placement = True)\n",
    "config.gpu_options.allow_growth = True\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "with tf.device('/gpu:1'):\n",
    "    initializer = tf.random_uniform_initializer(\n",
    "        -0.08, 0.08)\n",
    "    tf.get_variable_scope().set_initializer(initializer)\n",
    "    \n",
    "    x = tf.placeholder(\"int32\", [None, None])\n",
    "    y = tf.placeholder(\"int32\", [None, None])\n",
    "    y_in = tf.placeholder(\"int32\",[None,None])\n",
    "    \n",
    "    x_len = tf.placeholder(\"int32\",[None])\n",
    "    y_len = tf.placeholder(\"int32\",[None])\n",
    "    learning_rate = tf.placeholder(tf.float32, shape=[])\n",
    "    \n",
    "    # embedding\n",
    "    embedding_encoder = tf.get_variable(\n",
    "        \"embedding_encoder\", [src_vocab_size, embedding_size],dtype=tf.float32)\n",
    "    embedding_decoder = tf.get_variable(\n",
    "        \"embedding_decoder\", [target_vocat_size, embedding_size],dtype=tf.float32)\n",
    "    \n",
    "    encoder_emb_inp = tf.nn.embedding_lookup(\n",
    "        embedding_encoder, x)\n",
    "    decoder_emb_inp = tf.nn.embedding_lookup(\n",
    "        embedding_decoder, y_in)\n",
    "    \n",
    "    # encoder\n",
    "    num_bi_layers = int(layer_number / 2)\n",
    "    \n",
    "    # Build RNN cell\n",
    "    encoder_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)\n",
    "\n",
    "    # Run Dynamic RNN\n",
    "    #   encoder_outputs: [max_time, batch_size, num_units]\n",
    "    #   encoder_state: [batch_size, num_units]\n",
    "    encoder_outputs, encoder_state = tf.nn.dynamic_rnn(\n",
    "        encoder_cell, encoder_emb_inp,\n",
    "        sequence_length=x_len, time_major=False,dtype=tf.float32)\n",
    "        \n",
    "    \n",
    "    \n",
    "    batch_size_in = tf.shape(x)[0]\n",
    "    projection_layer = layers_core.Dense(\n",
    "        len(ch2ind), use_bias=False)\n",
    "    # Dynamic decoding\n",
    "    with tf.variable_scope(\"decode_layer\"):\n",
    "        # Build RNN cell\n",
    "        decoder_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)\n",
    "        # Helper\n",
    "        helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "            decoder_emb_inp, y_len, time_major=False)\n",
    "        # Decoder\n",
    "        decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "            decoder_cell, helper, encoder_state,\n",
    "            output_layer=projection_layer)\n",
    "        # Dynamic decoding\n",
    "        outputs, _ , __ = tf.contrib.seq2seq.dynamic_decode(decoder)\n",
    "        logits = outputs.rnn_output\n",
    "        target_weights = tf.sequence_mask(\n",
    "            y_len, seq_max_len, dtype=logits.dtype)\n",
    "    \n",
    "    # predicting\n",
    "    # Helper\n",
    "    with tf.variable_scope(\"decode_layer\", reuse=True):\n",
    "        # Helper\n",
    "        helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "            embedding_decoder,\n",
    "            tf.fill([batch_size_in], ch2ind['<start>']), ch2ind['<end>'])\n",
    "\n",
    "        # Decoder\n",
    "        decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "            decoder_cell, helper, encoder_state,\n",
    "            output_layer=projection_layer)\n",
    "        # Dynamic decoding\n",
    "        outputs, _ , __= tf.contrib.seq2seq.dynamic_decode(\n",
    "            decoder, maximum_iterations=maximum_iterations)\n",
    "        translations = outputs.sample_id\n",
    "        \n",
    "\n",
    "    # calculate loss\n",
    "    crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=y, logits=logits)\n",
    "    train_loss = (tf.reduce_sum(crossent * target_weights) /\n",
    "        tf.cast(batch_size_in,tf.float32))\n",
    "    \n",
    "    optimizer_ori = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    trainable_params = tf.trainable_variables()\n",
    "    gradients = tf.gradients(train_loss, trainable_params)\n",
    "    clip_gradients, _ = tf.clip_by_global_norm(gradients, max_grad)\n",
    "    global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "    optimizer = optimizer_ori.apply_gradients(\n",
    "            zip(clip_gradients, trainable_params), global_step=global_step)\n",
    "    #optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(train_loss)\n",
    "    #trainop = tflearn.TrainOp(loss=train_loss, optimizer=optimizer,\n",
    "    #                          metric=train_loss, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 512)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(encoder_emb_inp,feed_dict={\n",
    "    x:np.asarray(dat_x_in[:1])\n",
    "}).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_x_in = tf.keras.preprocessing.sequence.pad_sequences(dat_x_in,padding='post',value=en2ind['<eos>'])\n",
    "dat_y_in = tf.keras.preprocessing.sequence.pad_sequences(dat_y_in,padding='post',value=en2ind['<end>'])\n",
    "dat_y_out = tf.keras.preprocessing.sequence.pad_sequences(dat_y_out,padding='post',value=en2ind['<end>'])\n",
    "\n",
    "dat_x_len = np.asarray(dat_x_len)\n",
    "dat_y_len = np.asarray(dat_y_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((103912, 6), (103912, 6), (103912, 6), (103912,), (103912,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_x_in.shape,dat_y_in.shape,dat_y_out.shape,dat_x_len.shape,dat_y_len.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 40 batch 810 lr 7.62939453125e-06 loss 0.3124793767929077 99.90 % [=================================================>-] 103808/103912 \t used:280s eta:0 sss"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "beginning_lr = 4\n",
    "for one_epoch in range(0,40):\n",
    "    index = np.asarray(list(range(len(dat_x_in))))\n",
    "    np.random.shuffle(index)\n",
    "    pb = ProgressBar(worksum=len(index))\n",
    "    pb.startjob()\n",
    "    for i in range(0,len(index),batch_size):\n",
    "        batchindex = index[i:i + batch_size]\n",
    "        \n",
    "        batch_lr = beginning_lr if one_epoch < 20 else beginning_lr * 0.5 ** (one_epoch - 20)\n",
    "        if len(batchindex) < batch_size:\n",
    "            break\n",
    "        _,batch_loss = session.run([optimizer,train_loss],feed_dict={\n",
    "            x:dat_x_in[batchindex],\n",
    "            y:dat_y_out[batchindex],\n",
    "            y_in:dat_y_in[batchindex],\n",
    "\n",
    "            x_len:dat_x_len[batchindex],\n",
    "            y_len:dat_y_len[batchindex],\n",
    "            learning_rate:batch_lr,\n",
    "        })\n",
    "        pb.info = \"EPOCH {} batch {} lr {} loss {}\".format(one_epoch + 1,i // batch_size,batch_lr,batch_loss)\n",
    "        pb.complete(batch_size)\n",
    "        losses.append(batch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe14be27b50>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "pd.DataFrame(losses).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sent):\n",
    "    senttoken = [en2ind[i.lower()] for i in sent.split()]\n",
    "    senttoken.append(en2ind['<eos>'])\n",
    "    inputx = np.asarray([senttoken])\n",
    "    inputx_len = np.asarray([len(senttoken)])\n",
    "    print(inputx,inputx_len)\n",
    "    batch_translations = session.run(translations,feed_dict={\n",
    "            x:inputx,\n",
    "            x_len:inputx_len,\n",
    "        })[0]\n",
    "    return ''.join([ind2ch[i] for i in batch_translations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_sentence = \"i love shopping .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   7   84 1249    4    0]] [5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'我喜欢购。<end>'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(source_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/seq2seq_model'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(session,'models/seq2seq_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 yizhang  staff  53903364 Sep 27 23:19 models/seq2seq_model.data-00000-of-00001\n"
     ]
    }
   ],
   "source": [
    "! ls -l 'models/seq2seq_model.data-00000-of-00001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
